<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Arnav Jain, Nilesh Gupta, Aditya Kusupati, Jon Barron, Deepak Pathak and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f5b461;
  text-decoration:none;
  }
  body,td,th {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 16px;
     font-weight: 400
  }
  heading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 19px;
     font-weight: 600
  }
  strong {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 16px;
     font-weight: 800
  }
  strongred {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     color: 'red' ;
     font-size: 16px
  }
  sectionheading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 22px;
     font-weight: 600
  }
  pageheading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 60px;
     font-weight: 400
  }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/W.png"> -->
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Siba Smarak Panigrahi</title>
  <link rel = "icon" href = "images/McGill.png" type = "image/x-icon">
  <meta name="Siba Smarak Panigrahi" http-equiv="Content-Type" content="Siba Smarak Panigrahi">
  <!-- link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'> -->
  <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@200;300;400;600;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=PT+Sans:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <script type="text/javascript" src="js/toggle.js"></script>
  <!-- Start : Google Analytics Code -->
  <!-- <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90394621-1', 'auto');
  ga('send', 'pageview');

  </script> -->
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
<tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	<p align="left">
		<center><pageheading>Siba Smarak Panigrahi</pageheading><br>
		<b>&nbsp;Email</b>: <a href="mailto:siba.panigrahi@mail.mcgill.ca">siba.panigrahi@mail.mcgill.ca</a></center>
	</p>

	<tr>
		<td width="32%" valign="top"><a href="#Bio">
			<img src="images/me.jpg" width="100%" style="border-radius:15px"></a>
			<p align=center>
				<a href="resources/CV.pdf" target="_blank">CV</a> | <a href="https://scholar.google.co.in/citations?hl=en&user=X0n6DHoAAAAJ" target="_blank">Scholar</a> | <a href="https://github.com/sibasmarak" target="_blank">Github</a> | <a href="https://twitter.com/sibasmarak" target="_blank">Twitter</a> 
        <a href="https://www.linkedin.com/in/siba-smarak-panigrahi-42b38a213/" target="_blank"> LinkedIn </a> | <!-- <a href="https://www.instagram.com/siba_smarak/" target="_blank"> Instagram </a> | --> <a href="https://sibasmarak.blogspot.com/" target="_blank"> Literary works </a> |
        <a href="content/favorites.html" target="_blank"> Fun/Favorites </a> |
        <a href="content/gradappl.html" target="_blank"> Advice on Grad Applications </a> |
        <a href="content/montreal.html" target="_blank"> Montreal</a>
			</p>
		</td>

		<td width="68%" valign="top" align="justify" id="Bio">
			I am a first year M.Sc. (Thesis) student at <a href="https://www.mcgill.ca/" target="_blank">McGill University</a> and <a href="https://mila.quebec/" target="_blank">Mila</a> under the supervision of <a href="https://mila.quebec/en/person/siamak-ravanbakhsh/" target="_blank">Prof. Siamak Ravanbakhsh</a>.
      My research interests span representation Learning (on images and graphs), generative models, and multimodal learning
      <br><br>
      Previously, I was a Research Intern at <a href="https://www.microsoft.com/en-us/research/group/prose/" target="_blank">PROSE</a> at Microsoft, working on 
      designing algorithms and evaluation set-ups for email classification in real-world (online) settings. I was fortunate to work on topological data analysis at 
      <a href="https://research.adobe.com/careers/bangalore/" target="_blank">Adobe Research</a>, India and on explainability in pre-trained language models at
      <a href="https://inklab.usc.edu/" target="_blank">INK-Lab</a>, <a href="https://homeadmin.usc.edu/www/" target="_blank">University of Southern California</a>
      under <a href="https://shanzhenren.github.io/" target="_blank">Prof. Xiang Ren</a>.
      <br><br>
      I earned my B. Tech. in Computer Science and Engineering from <a href="http://www.iitkgp.ac.in/" target="_blank">Indian Institute of Technology Kharagpur</a>.
      I was part of the <a href="https://cvir.github.io/" target="_blank">CVIR</a> Lab under the supervision of 
      <a href="https://cse.iitkgp.ac.in/~adas/" target="_blank">Prof. Abir Das</a> and <a href="https://rpand002.github.io/" target="_blank">Dr. Rameswar Panda</a> where I worked on contextual 
      bias and multimodal learning problems.
		</td>
	</tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
	<tr><td id="Publications"> <sectionheading>&nbsp;&nbsp;News</sectionheading><div style="float: right;"></div></td></tr>
</table>
<table width="100%" align="center">
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Aug 22]</td>
    <td width="90%">One paper accepted in the <a href="https://blog.neurips.cc/2022/08/15/journal-showcase/" target="_blank">NeurIPS 2022 Journal Showcase Track</a> (also <b>NeurIPS Spotlight</b>)</td>
  </tr>
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Jul 22]</td>
    <td width="90%">Received <a href="https://www.jntataendowment.org/" target="_blank">J.N.Tata Endowment</a> and awarded 'JN Tata Scholar' title</td>
  </tr>
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [May 22]</td>
    <td width="90%">Selected to attend <a href="https://www.eeml.eu/" target="_blank">EEML</a> Summer School 2022</td>
  </tr>
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Apr 22]</td>
    <td width="90%">One paper accepted in the <a href="https://paperswithcode.com/rc2021" target="_blank">ML Reproducibility Challenge, 2021</a></td>
  </tr>
  <!-- <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Jan 22]</td>
    <td width="90%">Started working as a research intern </u></b> at <a href="https://www.microsoft.com/en-us/research/group/prose/" target="_blank"> PROSE</a> at Microsoft</td>
  </tr> -->
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Jan 22]</td>
    <td width="90%">Selected to attend <a href="https://sites.google.com/view/researchweek2022" target="_blank">Research Week with Google</a></td>
  </tr>
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Dec 21]</td>
    <td width="90%">Received the <a href="http://www1.iitkgp.ac.in/topfiles/sric" target="_blank">Prof. J.C. Ghosh Memorial Endowment Prize </a> for highest CGPA at the end of VI semester</td>
  </tr>
  <!-- <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Nov 21]</td>
    <td width="90%">Member of coding team (at IIT Kharagpur) for organizing a pan-India engineering entrance exam</td>
  </tr> -->
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Sep 21]</td>
    <td width="90%"> One paper accepted in the <a href="https://2021.argmining.org/" target="_blank">8th workshop on ArgumentMining at EMNLP 2021</a></td>
  </tr>
  <!-- <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [May 21]</td>
    <td width="90%">Started working as research intern at <a href="https://research.adobe.com/careers/bangalore/" target="_blank">Adobe Research, India</a> on Topological Data Analysis</td>
  </tr>
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [May 21]</td>
    <td width="90%">Accepted in IUSSTF-Viterbi program to intern at <a href="https://inklab.usc.edu/" target="_blank">INK-Lab</a> under <a href="https://shanzhenren.github.io/" target="_blank">Prof. Xiang Ren</a></td>
  </tr> -->
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Dec 20]</td>
    <td width="90%">One paper accepted in the <a href="https://computingconf.com/2020/" target="_blank">10th International Advance Computing Conference (IACC 2020)</a></td>
  </tr>
  <tr>
    <td width="10%">&nbsp;&nbsp;&nbsp;&nbsp; [Jun 19]</td>
    <td width="90%">Received the <a href="http://www1.iitkgp.ac.in/topfiles/sric" target="_blank"> Technology Alumni Association Award </a> for highest CGPA at the end of II semester</td>
  </tr>
</table>




<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
	<tr><td id="Publications"> <sectionheading>&nbsp;&nbsp;Publications</sectionheading><div style="float: right;"></div></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
		<td width="33%" valign="top" align="center"><a href="https://zenodo.org/record/6574687/files/article.pdf" target="_blank"><img src="images/VavRC2021.png" alt="VavRC2021" width="100%" style="border-radius:1px"></a></td>
		<td width="67%" valign="top">
			<p>
        <a href="https://zenodo.org/record/6574687/files/article.pdf" target="_blank" id="VavRC2021">
				<heading>[Re]: Value Alignment Verification</heading></a><br>
				<strong>Siba Smarak Panigrahi</strong>*, Sohan Patnaik*<br>
				The ML Reproducibility Challenge (<b>MLRC</b>), 2021;<br>
        <b>NeurIPS</b> Journal Showcase Track, 2022; <b>NeurIPS</b> Spotlight, 2022<br>
			</p>
			<!-- Long Oral presentation<br> -->
			<div class="paper" id="panigrahi2022re">
				<!-- <a href="javascript:toggleblock('Saini21abs')">abstract</a> / -->
				<!-- <a shape="rect" href="javascript:togglebib('panigrahi2022re')" class="togglebib">bibtex</a> / -->
				<a href="https://zenodo.org/record/6574687/files/article.pdf" target="_blank">pdf</a> /
				<a href="https://github.com/AIExL/vav_rc2021" target="_blank">code</a>
				<br>
				<!-- <p align="justify" > <i id="Saini21abs">This paper develops the GalaXC algorithm for Extreme Classification, where the task is to annotate a document with the most relevant subset of labels from an extremely large label set. Extreme classification has been successfully applied to several real world web-scale applications such as web search, product recommendation, query rewriting, etc. GalaXC identifies two critical deficiencies in leading extreme classification algorithms. First, existing approaches generally assume that documents and labels reside in disjoint sets, even though in several applications, labels and documents cohabit the same space. Second, several approaches, albeit scalable, do not utilize various forms of metadata offered by applications, such as label text and label correlations. To remedy these, GalaXC presents a framework that enables collaborative learning over joint document-label graphs at massive scales, in a way that naturally allows various auxiliary sources of information, including label metadata, to be incorporated. GalaXC also introduces a novel label-wise attention mechanism to meld high-capacity extreme classifiers with its framework. An efficient end-to-end implementation of GalaXC is presented that could be trained on a dataset with 50M labels and 97M training documents in less than 100 hours on 4xV100 GPUs. This allowed GalaXC to not only scale to applications with several millions of labels, but also be up to 18% more accurate than leading deep extreme classifiers, while being upto 2-50x faster to train and 10x faster to predict on benchmark datasets. GalaXC is particularly well-suited to warm-start scenarios where predictions need to be made on data points with partially revealed label sets, and was found to be up to 25% more accurate than extreme classification algorithms specifically designed for warm start settings. In A/B tests conducted on the Bing search engine, GalaXC could improve the Click Yield (CY) and coverage by 1.52% and 1.11% respectively. Code for GalaXC is available at <a href="https://github.com/Extreme-classification/GalaXC">https://github.com/Extreme-classification/GalaXC</a>.</i></p> -->

        <!-- <pre xml:space="preserve">
          @inproceedings{panigrahi2022re,
            title           = {[Re]: Value Alignment Verification},
            author          = {Siba Smarak Panigrahi and Sohan Patnaik},
            booktitle       = {ML Reproducibility Challenge 2021 (Fall Edition)},
            year            = 2022,
            url             = {https://openreview.net/forum?id=BFLM3nMmhCt}
          }
          </pre> -->
	      </div>
     	</td>
  	</tr>

    <tr>
      <td width="33%" valign="top" align="center"><a href="https://aclanthology.org/2021.argmining-1.21.pdf" target="_blank"><img src="images/ArgminingEMNLP2021.png" alt="ArgminingEMNLP2021" width="100%" style="border-radius:1px"></a></td>
      <td width="67%" valign="top">
        <p>
          <a href="https://aclanthology.org/2021.argmining-1.21.pdf" target="_blank" id="ArgminingEMNLP2021">
          <heading>Leveraging Pretrained Language Models for Key Point Matching</heading></a><br>
          Manav Nitin Kapadnis*, Sohan Patnaik*, <strong>Siba Smarak Panigrahi</strong>, Varun Madhavan, and Abhilash Nandy<br>
          8th workshop on ArgumentMining at Empirical Methods in Natural Language Processing (<b>EMNLP</b>), 2021<br>
        </p>
        <!-- Long Oral presentation<br> -->
        <div class="paper" id="kapadnis-etal-2021-team">
          <!-- <a href="javascript:toggleblock('Saini21abs')">abstract</a> / -->
          <!-- <a shape="rect" href="javascript:togglebib('kapadnis-etal-2021-team')" class="togglebib">bibtex</a> / -->
          <a href="https://aclanthology.org/2021.argmining-1.21.pdf" target="_blank">pdf</a> /
          <a href="https://github.com/manavkapadnis/Enigma_ArgMining" target="_blank">code</a>
          <br>
          <!-- <p align="justify" > <i id="Saini21abs">This paper develops the GalaXC algorithm for Extreme Classification, where the task is to annotate a document with the most relevant subset of labels from an extremely large label set. Extreme classification has been successfully applied to several real world web-scale applications such as web search, product recommendation, query rewriting, etc. GalaXC identifies two critical deficiencies in leading extreme classification algorithms. First, existing approaches generally assume that documents and labels reside in disjoint sets, even though in several applications, labels and documents cohabit the same space. Second, several approaches, albeit scalable, do not utilize various forms of metadata offered by applications, such as label text and label correlations. To remedy these, GalaXC presents a framework that enables collaborative learning over joint document-label graphs at massive scales, in a way that naturally allows various auxiliary sources of information, including label metadata, to be incorporated. GalaXC also introduces a novel label-wise attention mechanism to meld high-capacity extreme classifiers with its framework. An efficient end-to-end implementation of GalaXC is presented that could be trained on a dataset with 50M labels and 97M training documents in less than 100 hours on 4xV100 GPUs. This allowed GalaXC to not only scale to applications with several millions of labels, but also be up to 18% more accurate than leading deep extreme classifiers, while being upto 2-50x faster to train and 10x faster to predict on benchmark datasets. GalaXC is particularly well-suited to warm-start scenarios where predictions need to be made on data points with partially revealed label sets, and was found to be up to 25% more accurate than extreme classification algorithms specifically designed for warm start settings. In A/B tests conducted on the Bing search engine, GalaXC could improve the Click Yield (CY) and coverage by 1.52% and 1.11% respectively. Code for GalaXC is available at <a href="https://github.com/Extreme-classification/GalaXC">https://github.com/Extreme-classification/GalaXC</a>.</i></p> -->
  
          <!-- <pre xml:space="preserve">
            @inproceedings{kapadnis-etal-2021-team,
              title = "Team Enigma at {A}rg{M}ining-{EMNLP} 2021: Leveraging Pre-trained Language Models for Key Point Matching",
              author = "Kapadnis, Manav  and
                Patnaik, Sohan  and
                Panigrahi, Siba  and
                Madhavan, Varun  and
                Nandy, Abhilash",
              booktitle = "Proceedings of the 8th Workshop on Argument Mining",
              year = "2021",
              url = "https://aclanthology.org/2021.argmining-1.21",
            }
            </pre> -->
          </div>
         </td>
      </tr>

      <tr>
        <td width="33%" valign="top" align="center"><a href="https://link.springer.com/chapter/10.1007%2F978-981-16-0401-0_38" target="_blank"><img src="images/EmotionIACC2020.PNG" alt="EmotionIACC2020" width="100%" style="border-radius:1px"></a></td>
        <td width="67%" valign="top">
          <p>
            <a href="https://link.springer.com/chapter/10.1007%2F978-981-16-0401-0_38" target="_blank" id="EmotionIACC2020">
            <heading>Multi-class Emotion Classification Using EEG Signals</heading></a><br>
            Divya Acharya, Riddhi Jain, <strong>Siba Smarak Panigrahi</strong>, Rahul Sahni, Siddhi Jain, Sanika Prashant Deshmukh, and Arpit Bhardwaj<br>
            10th International Advance Computing Conference (<b>IACC</b>), 2020<br>
          </p>
          <!-- Long Oral presentation<br> -->
          <div class="paper" id="Acharya20">
            <!-- <a href="javascript:toggleblock('Saini21abs')">abstract</a> / -->
            <!-- <a shape="rect" href="javascript:togglebib('Acharya20')" class="togglebib">bibtex</a> / -->
            <a href="https://link.springer.com/chapter/10.1007%2F978-981-16-0401-0_38" target="_blank">pdf</a> /
            <a href="https://github.com/sibasmarak/Emotion-Recognition-from-brain-EEG-signals-" target="_blank">code</a>
            <br>
            <!-- <p align="justify" > <i id="Saini21abs">This paper develops the GalaXC algorithm for Extreme Classification, where the task is to annotate a document with the most relevant subset of labels from an extremely large label set. Extreme classification has been successfully applied to several real world web-scale applications such as web search, product recommendation, query rewriting, etc. GalaXC identifies two critical deficiencies in leading extreme classification algorithms. First, existing approaches generally assume that documents and labels reside in disjoint sets, even though in several applications, labels and documents cohabit the same space. Second, several approaches, albeit scalable, do not utilize various forms of metadata offered by applications, such as label text and label correlations. To remedy these, GalaXC presents a framework that enables collaborative learning over joint document-label graphs at massive scales, in a way that naturally allows various auxiliary sources of information, including label metadata, to be incorporated. GalaXC also introduces a novel label-wise attention mechanism to meld high-capacity extreme classifiers with its framework. An efficient end-to-end implementation of GalaXC is presented that could be trained on a dataset with 50M labels and 97M training documents in less than 100 hours on 4xV100 GPUs. This allowed GalaXC to not only scale to applications with several millions of labels, but also be up to 18% more accurate than leading deep extreme classifiers, while being upto 2-50x faster to train and 10x faster to predict on benchmark datasets. GalaXC is particularly well-suited to warm-start scenarios where predictions need to be made on data points with partially revealed label sets, and was found to be up to 25% more accurate than extreme classification algorithms specifically designed for warm start settings. In A/B tests conducted on the Bing search engine, GalaXC could improve the Click Yield (CY) and coverage by 1.52% and 1.11% respectively. Code for GalaXC is available at <a href="https://github.com/Extreme-classification/GalaXC">https://github.com/Extreme-classification/GalaXC</a>.</i></p> -->
    
            <!-- <pre xml:space="preserve">
              @inproceedings{Acharya20,
                title = "Team Enigma at {A}rg{M}ining-{EMNLP} 2021: Leveraging Pre-trained Language Models for Key Point Matching",
                author = "Kapadnis, Manav  and
                  Patnaik, Sohan  and
                  Panigrahi, Siba  and
                  Madhavan, Varun  and
                  Nandy, Abhilash",
                booktitle = "Proceedings of the 8th Workshop on Argument Mining",
                year = "2021",
                url = "https://aclanthology.org/2021.argmining-1.21",
              }
              </pre> -->
            </div>
           </td>
        </tr>


        
          

        
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
     <tr><td><br><p align="right"><font size="2">
     Template: <a href="https://arnavkj1995.github.io/">this</a> 
    </font></p></td></tr>
    <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fsibasmarak.github.io&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
</table>

</td></tr>
</table>

<!-- <script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('Saini21abs');
</script>
<script xml:space="preserve" language="JavaScript">
    hideblock('Lahiri20abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('Lahiri19abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('Agarwalla18abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('Jain17abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('acknowledgements');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('gradschool');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('quotes');
</script> -->



</body>

</html>
